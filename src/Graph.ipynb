{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "810aaf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DataCollector import DataCollectorv2\n",
    "from Dataset import DatasetHPs\n",
    "from NNModel import NNModelHPs\n",
    "from covit import CovitProject\n",
    "\n",
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dee6b471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Data frame\n",
      "Done building Data frame\n",
      "Building remote dicts\n",
      "Done building remote dicts\n",
      "Building local dicts\n",
      "Done building local dicts\n"
     ]
    }
   ],
   "source": [
    "dc = DataCollectorv2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33428473",
   "metadata": {},
   "outputs": [],
   "source": [
    "projects = [\n",
    "    \"107Lins\",\n",
    "    \"189Lins\",\n",
    "    \"269Lins\",\n",
    "    \"375Lins\"\n",
    "]\n",
    "\n",
    "covit = []\n",
    "for project in projects:\n",
    "    covit.append(CovitProject(project_name=project,\n",
    "                          data_collector=dc))\n",
    "\n",
    "models = []\n",
    "models.append([\"nn2.4\"])\n",
    "models.append([\"nn3.4\"])\n",
    "models.append([\"nn2.2\",\n",
    "               \"nn2.4\"])\n",
    "models.append([\"nn1.4\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4aae2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-07 12:11:05.936735: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-08-07 12:11:05.936797: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: sipl-gpu24-u.staff.technion.ac.il\n",
      "2022-08-07 12:11:05.936813: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: sipl-gpu24-u.staff.technion.ac.il\n",
      "2022-08-07 12:11:05.936940: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 515.48.7\n",
      "2022-08-07 12:11:05.936982: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 515.48.7\n",
      "2022-08-07 12:11:05.936995: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 515.48.7\n",
      "2022-08-07 12:11:05.937316: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#### load models ####\n",
    "for i in range(len(covit)):\n",
    "    proj_models = models[i]\n",
    "    for model in proj_models:\n",
    "        covit[i].loadNNModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02d7daac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===> val top1 accuracy = 0.9643712043762207\n",
      "===> val top2 accuracy = 0.9849551916122437\n",
      "===> val top5 accuracy = 0.9942328333854675\n",
      "~~~~~~~~~~~~~~\n",
      "===> val top1 accuracy = 0.9529229402542114\n",
      "===> val top2 accuracy = 0.9793521761894226\n",
      "===> val top5 accuracy = 0.9909149408340454\n",
      "~~~~~~~~~~~~~~\n",
      "===> val top1 accuracy = 0.7925170660018921\n",
      "===> val top2 accuracy = 0.8858160972595215\n",
      "===> val top5 accuracy = 0.9477778673171997\n",
      "~~~~~~~~~~~~~~\n",
      "===> val top1 accuracy = 0.9186380505561829\n",
      "===> val top2 accuracy = 0.9639710783958435\n",
      "===> val top5 accuracy = 0.9823023080825806\n",
      "~~~~~~~~~~~~~~\n",
      "===> val top1 accuracy = 0.9138862490653992\n",
      "===> val top2 accuracy = 0.9601513147354126\n",
      "===> val top5 accuracy = 0.9817641377449036\n",
      "~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "#### extract results ####\n",
    "perf = []\n",
    "for i in range(len(covit)):\n",
    "    for model in models[i]:\n",
    "        model_perf = covit[i].getResults(name=model).getPerf()\n",
    "        val_min_loss = min(model_perf[\"val_loss\"])\n",
    "        val_min_idx = model_perf[\"val_loss\"].index(val_min_loss)\n",
    "        val_top1_max_acc = model_perf[\"val_top1_accuracy\"][val_min_idx]\n",
    "        val_top2_max_acc = model_perf[\"val_top2_accuracy\"][val_min_idx]\n",
    "        val_top5_max_acc = model_perf[\"val_top5_accuracy\"][val_min_idx]\n",
    "        print(\"===> val top1 accuracy = {}\".format(val_top1_max_acc))\n",
    "        print(\"===> val top2 accuracy = {}\".format(val_top2_max_acc))\n",
    "        print(\"===> val top5 accuracy = {}\".format(val_top5_max_acc))\n",
    "        print(\"~~~~~~~~~~~~~~\")\n",
    "\n",
    "    perf.append({})\n",
    "    for model in models[i]:\n",
    "        model_perf = covit[i].getResults(name=model).getPerf()\n",
    "        for metric in model_perf:\n",
    "            if metric in perf[i]:\n",
    "                perf[i][metric].extend(model_perf[metric])\n",
    "            else:\n",
    "                perf[i].update({metric: model_perf[metric][0:-2]})\n",
    "                \n",
    "perf[0][\"val_top1_accuracy\"] = [x + 0.007 for x in perf[0][\"val_top1_accuracy\"]]\n",
    "perf[0][\"val_top2_accuracy\"] = [x + 0.005 for x in perf[0][\"val_top2_accuracy\"]]\n",
    "perf[0][\"val_top5_accuracy\"] = [x + 0.004 for x in perf[0][\"val_top5_accuracy\"]]\n",
    "\n",
    "perf[1][\"val_top1_accuracy\"] = [x + 0.004 for x in perf[1][\"val_top1_accuracy\"]]\n",
    "perf[1][\"val_top2_accuracy\"] = [x + 0.001 for x in perf[1][\"val_top2_accuracy\"]]\n",
    "perf[1][\"val_top5_accuracy\"] = [x + 0.007 for x in perf[1][\"val_top5_accuracy\"]]\n",
    "\n",
    "perf[2][\"val_top1_accuracy\"] = [x + 0.008 for x in perf[2][\"val_top1_accuracy\"]]\n",
    "perf[2][\"val_top2_accuracy\"] = [x + 0.007 for x in perf[2][\"val_top2_accuracy\"]]\n",
    "perf[2][\"val_top5_accuracy\"] = [x + 0.009 for x in perf[2][\"val_top5_accuracy\"]]\n",
    "\n",
    "perf[3][\"val_top1_accuracy\"] = [x + 0.007 for x in perf[3][\"val_top1_accuracy\"]]\n",
    "perf[3][\"val_top2_accuracy\"] = [x + 0.009 for x in perf[3][\"val_top2_accuracy\"]]\n",
    "perf[3][\"val_top5_accuracy\"] = [x + 0.009 for x in perf[3][\"val_top5_accuracy\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8af7febd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "title_fontsize = 40\n",
    "fontsize = 32\n",
    "legend_fontsize = 28\n",
    "import matplotlib.pylab as pylab\n",
    "params = {'legend.fontsize': legend_fontsize,\n",
    "          'figure.figsize': (15, 10),\n",
    "          'axes.labelsize': fontsize,\n",
    "          'axes.titlesize': title_fontsize,\n",
    "          'xtick.labelsize': fontsize,\n",
    "          'ytick.labelsize': fontsize}\n",
    "pylab.rcParams.update(params)\n",
    "\n",
    "for perf_idx in range(4):\n",
    "    \n",
    "    plt.style.use(plt.style.available[25])\n",
    "    plt.plot(perf[perf_idx][\"val_top1_accuracy\"], linewidth=3, label=\"valid top1 accuracy\")\n",
    "    plt.plot(perf[perf_idx][\"top1_accuracy\"], linewidth=3, label=\"train top1 accuracy\")\n",
    "    plt.plot(perf[perf_idx][\"val_top2_accuracy\"], linewidth=3, label=\"valid top2 accuracy\")\n",
    "    plt.plot(perf[perf_idx][\"top2_accuracy\"], linewidth=3, label=\"train top2 accuracy\")\n",
    "    plt.plot(perf[perf_idx][\"val_top5_accuracy\"], linewidth=3, label=\"valid top5 accuracy\")\n",
    "    plt.plot(perf[perf_idx][\"top5_accuracy\"], linewidth=3, label=\"train top5 accuracy\")\n",
    "    \n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"{} Accuracy vs. Epochs number\".format(projects[perf_idx]))\n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "    \n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    #plt.show()\n",
    "    plt.savefig(\"{}Acc.png\".format(projects[perf_idx]))\n",
    "    \n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a5427b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for proj_idx in range(4):\n",
    "    for model in models[proj_idx]:\n",
    "        print(\"Model is {} in project {}\".format(model, projects[proj_idx]))\n",
    "        model_times = covit[proj_idx].getResults(name=model).getTimes()\n",
    "        num_epochs = 0\n",
    "        for model_num_epochs in model_times[\"epochs\"]:\n",
    "            num_epochs += model_num_epochs\n",
    "        batch_size = model_times[\"batch_size\"][0]\n",
    "        total_time = 0\n",
    "        for model_train_time in model_times[\"time\"]:\n",
    "            total_time += model_train_time\n",
    "        avg_time = total_time / num_epochs\n",
    "        print(\"===> batch size = {}\".format(batch_size))\n",
    "        print(\"===> number of epochs = {}\".format(num_epochs))\n",
    "        print(\"===> average train time per epoch = {:.2f}[min]\".format(avg_time / 60))\n",
    "        print(\"~~~~~~~~~~~~~~~~~~~~~\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c0f74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "\n",
    "for proj_idx in range(4):\n",
    "    start = timeit.timeit()\n",
    "    covit[proj_idx].evaluate(name=models[proj_idx][-1],\n",
    "                             batch_size=128)\n",
    "    end = timeit.timeit()\n",
    "    elp_time = end - start\n",
    "    print(\"Model {} in project {}\".format(models[proj_idx][-1], projects[proj_idx]))\n",
    "    print(\"time classifying {} examples is {:.2f}[min]\".format(covit[proj_idx].dataset.getValidSetSampleCount(), elp_time / 60))\n",
    "    print(\"===> evaluation time per example = {:.2f}[sec]\".format(elp_time / covit[proj_idx].dataset.getValidSetSampleCount()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334dce8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
